\section*{Delivery Mechanism and Community Usage Metrics}

% - 2 page limit
\subsection*{Deliverables}

\subsubsection*{Access Pathways}

This project will create OpenEarthscape as an open-source collection of tools, libraries, standards, and resources. The OpenEarthscape suite will be hosted on the CSDMS web portal, with a gateway to OpenEarthscape prominently displayed on the landing page (portal: csdms.colorado.edu). This gateway will lead to a high-level description, with links to the various tools and collections. These pointers will lead to web landing pages specific to individual resources; for example, the EarthscapeHub, the OpenEarthscape Simulator, Reproducibility Resource Shop, SVO, BMI, etc. In general, documentation pages for individual tools and products will be developed in Sphinx and deployed on \texttt{readthedocs}. Each product landing page will feature ``quick start'' resources (e.g., tutorials, videos). Tutorials, including those arising from science demonstration projects, will take the form of Jupyter Notebooks, and be accessible and operable via the OpenEarthscape JupyterHub. Source code will be hosted in public GitHub repositories.

\subsubsection*{Awareness Pathways}

In order to take advantage of OpenEarthscape resources, the communities need to know about them. Marketing efforts will include: (1) presentations at conferences; (2) clinics at conferences (e.g., CUAHSI, CSDMS, Gateways, SIAM); (3) presentations and publications by research partners and summer-science students; (4) promotion on social media (especially twitter); (5) CSDMS Quarterly Newsletters (using MailChimp to tracks of open and click-through rates).

Inspired by the reporting on metrics used by Science Gateways \citep{wilkins2019measuring}, we divide our Metrics of Success into the following categories: %Awareness, Usage and adoption, Tool development, Training, Supporting new users, Users beyond those trained by the team, and Application to Science. Metrics by category include:

\textit{\textbf{Awareness}}: Web hits on the simulator (at least 100 non-developer hits in the release year, with steady year-by-year increase subsequently), meetings of the OpenEarthscape Software Council (annual, plus any special events), and participants at those meetings (at least 6), and papers and presentations using OpenEarthscape tools (at least one presentation per tool in the year of or following initial release; 2--4 presentations by partners in the following 2 years, depending on the item; papers will likely lag releases by 2--3 years, but we conservatively expect about one summer-student-led paper in year 3 and two in years 4 and 5).

\textit{\textbf{Usage and Adoption}}: Returning and active users of Cloud resources (tens of total annual users initially; at least hundreds annual total and tens of annual returning users by project end), number of papers using OpenEarthscape software (see above), software downloads (thousands), contributions to the Whole Tale repository (dozens), number of graduate students visiting OpenEarthscape (at least 3/year, years 1--4), numbers of papers and presentations by non-team members (see above), workshops with summer internship students from underrepresented groups (at least 25 per year, depending on program enrollment).

\textit{\textbf{Tool Development}}: Software releases (major and minor, with first releases following timeline in \textit{Management and Coordination Plan}), documentation and tutorials of software components (Sphinx doc pages and at least one tutorial per component), issues logged and resolved against OpenEarthscape software (average issue resolution time $\le$1 week).

\textit{\textbf{Training}}: Number of clinics/workshops and attendees (average of one event per year, with average of $\ge$12 attendees), diversity statistics for participants (reflective of professional society membership, if not of US population). Users beyond those trained by the team: number of papers and presentations by non-team members (difficult to predict but expect at least 3 independent published uses by project end).%, classes taught on \textit{Lab}, and total enrollment in those classes.

In addition to these four primary categories, we will also track research applications, with the expectation of  resentations or publications that represent at least 5 different disciplines or subdisciplines by project end; and  publications spanning $\ge$5 different journals.

OpenEarthscape will implement a strategy of continual testing and adaption of the identified metrics by analyzing them quarterly at PI team meetings, and providing an annual status report to its Steering Committee on these metrics. %, and conducting exit interviews with summer visiting students.  
In addition,  OpenEarthscape will present results of feedback and metrics at a Science Gateways Community Institute (SGCI) Annual Meeting.  
%presentations by non-team members, reach XXX students from underrepresented groups for internships.


\subsubsection*{Yearly Metrics}

We will compare annual metrics to the following milestones. If indications of progress or adoption are lagging, we will examine potential causes and correct as needed. For example, lower than expected adoption of a given tool could indicate a need for increased marketing efforts.

\scitem{Year 1:} OpenEarthscape Council: 6--10 inaugural members. EarthscapeHub: use by at least three workshops and/or classes. BMI for Julia: templates, documentation, and tutorial example. Other tutorials on the web portal and EarthscapeHub: SVO, coupling agent-based and process models, reproducibility with WholeTale. Parallel-capability Landlab marine components: code, at least 80\% test coverage, basic docs, tutorial. Scientific computing workshops for undergraduate internship programs: 25 or more students depending on program enrollment. 3 visiting grad students.

\scitem{Year 2:} EarthscapeHub: use by at least dozens, of which at least 10 are returning. Earthscape Simulator: tens of hits on prototype. Tech achievements: BMI for WRF-Hydro, \texttt{CoupledModel} base class for PyMT components, Landlab \texttt{GlobalGrid} class, BMI parallel extensions, visualization pathways (utilities and  tutorials). Summer  computing workshops ($\ge$25 students); visiting grad student program (3 students). At least 1 conference presentation arising from summer project in year 1. BMI should be in use by at least 3 research groups.

\scitem{Year 3:} EarthscapeHub: use by at least dozens, of which at least 20 are returning. Earthscape Simulator: should have 50--100\% hits relative to year 2. Tech achievements: BMI for Octave, BMI for SiSTER, test SiSTER parallel coupling, search capability for SVO, Landlab parallel refactor. Reproducibility: at least 5 projects using the pathway. Summer  computing workshops ($\ge$25 students); visiting grad student program (3 students). At least 3 conference presentations and/or papers submitted arising from prior year summer projects and partnerships.

\scitem{Year 4:} 
EarthscapeHub: use by at least dozens, of which at least 20 are returning. Earthscape Simulator: continued steady increase in hit rate. Tech achievements: apply BMI for an agent-based model, tool for interactive generation of Standard Names, BMI for hydrologic models. Landlab \texttt{GlobalGrid} class. Reproducibility: at least 10 projects. Summer computing workshops ($\ge$25 students); visiting grad student program (3 students). At least 4 conference presentations and/or papers submitted arising from prior year summer projects and partnerships. BMI should be in use by at least 5 research groups.

\scitem{Year 5:} 
EarthscapeHub: $>$100 annual total users, and $>$20 returning. Earthscape Simulator: continued steady increase in hit rate. Tech achievements: BMI extension for data assimilation, Landlab \texttt{Grid3D} class. Summer computing workshops ($\ge$25 students). At least 4 conference presentations and/or papers submitted arising from prior year summer projects and partnerships.
